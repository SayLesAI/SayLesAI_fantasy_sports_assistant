{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data wrangling\n",
    "\n",
    "Since the data tables on the [Footballguys](https://www.footballguys.com/) website are fully rendered in HTML, we might be able to scrape the data without too much trouble. This gives us good control over exactly what data we download and an easy mechanism by which to update it throughout the season. Let's give it a try using [urllib](https://docs.python.org/3/howto/urllib2.html) and [BeautifulSoup](https://beautiful-soup-4.readthedocs.io/en/latest/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import urllib.request\n",
    "from itertools import product\n",
    "from random import randrange\n",
    "\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Decide if we want to re-download the data or not\n",
    "download_data=True\n",
    "\n",
    "# Set the data file paths\n",
    "raw_data_path='../data/raw_qb_data.parquet'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Download and parse HTML data\n",
    "\n",
    "The available data spans 1996 to 2024 and each year has 18 weeks of data. We also will want to download the data for multiple positions. But, let's start with just one. We also need to pick a scoring scheme, let's go with PPR. We can easily change this later. We will use a loop to construct and download the URL for each year and week and parse and collect the data as we get it.\n",
    "\n",
    "**Note**: Downloading all of the data for one position takes just over 45 minutes.\n",
    "\n",
    "### 1.1. Download function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_url(url: str) -> bytes:\n",
    "    '''Takes string url, downloads URL and returns HTML bytes object'''\n",
    "\n",
    "    headers={\n",
    "        \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7\",\n",
    "        \"Accept-Language\": \"en-US,en;q=0.9\",\n",
    "        \"Connection\": \"keep-alive\",\n",
    "        \"Host\": \"httpbin.io\",\n",
    "        \"Sec-Ch-Ua\": '\"Google Chrome\";v=\"131\", \"Chromium\";v=\"131\", \"Not_A Brand\";v=\"24\"',\n",
    "        \"Sec-Ch-Ua-Mobile\": \"?0\",\n",
    "        \"Sec-Ch-Ua-Platform\": '\"Linux\"',\n",
    "        \"Sec-Fetch-Dest\": \"document\",\n",
    "        \"Sec-Fetch-Mode\": \"navigate\",\n",
    "        \"Sec-Fetch-Site\": \"cross-site\",\n",
    "        \"Sec-Fetch-User\": \"?1\",\n",
    "        \"Upgrade-Insecure-Requests\": \"1\",\n",
    "        \"User-Agent\": \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36\"\n",
    "    }\n",
    "\n",
    "    # Create the request\n",
    "    request_params = urllib.request.Request(\n",
    "        url=url,\n",
    "        headers=headers\n",
    "    )   \n",
    "\n",
    "    # Get the html\n",
    "    with urllib.request.urlopen(request_params) as response:\n",
    "        html=response.read()\n",
    "\n",
    "    return html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. HTML parsing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_html_table(html: bytes, position: str, year: int, week: int, profile: str) -> pd.DataFrame:\n",
    "    '''Takes a html bytes object from URL, parses data table, adds\n",
    "    year, week, position and scoring profile and returns as pandas dataframe'''\n",
    "\n",
    "    # Extract the table rows\n",
    "    soup=BeautifulSoup(html, 'html.parser')\n",
    "    table=soup.find('table',{'class':'datasmall table'})\n",
    "    table_rows=table.find_all('tr')\n",
    "\n",
    "    # Get the column names from the first row\n",
    "    columns=table_rows[0].find_all('th')\n",
    "    column_names=[column.getText() for column in columns]\n",
    "    column_names.extend(['Position', 'Year', 'Week', 'Scoring profile'])\n",
    "\n",
    "    # Get the values for each row\n",
    "    data=[]\n",
    "\n",
    "    for row in table_rows[1:]:\n",
    "        columns=row.find_all('td')\n",
    "        values=[column.getText() for column in columns]\n",
    "        values.extend([position, year, week, profile])\n",
    "        data.append(values)\n",
    "\n",
    "    # Convert to pandas dataframe and return\n",
    "    return pd.DataFrame(columns=column_names, data=data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Main download loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data for 2024\r"
     ]
    }
   ],
   "source": [
    "# URL parameter arguments\n",
    "position='qb'\n",
    "profile='p'\n",
    "years=list(range(1996,2025))\n",
    "weeks=list(range(1,19))\n",
    "\n",
    "# Download the data if asked\n",
    "if download_data is True:\n",
    "\n",
    "    # Empty list to accumulate results\n",
    "    results=[]\n",
    "\n",
    "    for year, week in product(years, weeks):\n",
    "\n",
    "        print(f'Downloading data for {year}', end='\\r')\n",
    "\n",
    "        # Construct the URL for this year and week\n",
    "        url=f'https://www.footballguys.com/playerhistoricalstats?pos={position}&yr={year}&startwk={week}&stopwk={week}&profile={profile}'\n",
    "\n",
    "        # Get the HTML\n",
    "        html=download_url(url)\n",
    "\n",
    "        # Parse the HTML\n",
    "        result=parse_html_table(html, position, year, week, profile)\n",
    "\n",
    "        # Collect the result\n",
    "        results.append(result)\n",
    "\n",
    "        # Wait before downloading the next page\n",
    "        time.sleep(randrange(1, 10))\n",
    "\n",
    "    # Combine the week by week dataframes\n",
    "    data_df=pd.concat(results)\n",
    "\n",
    "    # Clean up the index\n",
    "    data_df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "    # Save as parquet\n",
    "    data_df.to_parquet(raw_data_path)\n",
    "\n",
    "# Or load it from disk if we already have it\n",
    "if download_data is False:\n",
    "    data_df=pd.read_parquet(raw_data_path)\n",
    "    print('Loaded data from disk')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Fix the player name/team column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>Exp</th>\n",
       "      <th>G</th>\n",
       "      <th>Cmp</th>\n",
       "      <th>Att</th>\n",
       "      <th>Cm%</th>\n",
       "      <th>PYd</th>\n",
       "      <th>Y/Att</th>\n",
       "      <th>...</th>\n",
       "      <th>Rsh</th>\n",
       "      <th>RshYd</th>\n",
       "      <th>RshTD</th>\n",
       "      <th>FP/G</th>\n",
       "      <th>FantPt</th>\n",
       "      <th>Position</th>\n",
       "      <th>Year</th>\n",
       "      <th>Week</th>\n",
       "      <th>Scoring profile</th>\n",
       "      <th>Team</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Brett Favre</td>\n",
       "      <td>27.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>27</td>\n",
       "      <td>74.1</td>\n",
       "      <td>247</td>\n",
       "      <td>9.15</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>qb</td>\n",
       "      <td>1996</td>\n",
       "      <td>1</td>\n",
       "      <td>p</td>\n",
       "      <td>GB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Mark Brunell</td>\n",
       "      <td>26.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>31</td>\n",
       "      <td>64.5</td>\n",
       "      <td>212</td>\n",
       "      <td>6.84</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>20.6</td>\n",
       "      <td>20.6</td>\n",
       "      <td>qb</td>\n",
       "      <td>1996</td>\n",
       "      <td>1</td>\n",
       "      <td>p</td>\n",
       "      <td>JAX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Vinny Testaverde</td>\n",
       "      <td>33.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>33</td>\n",
       "      <td>57.6</td>\n",
       "      <td>254</td>\n",
       "      <td>7.70</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "      <td>20.4</td>\n",
       "      <td>20.4</td>\n",
       "      <td>qb</td>\n",
       "      <td>1996</td>\n",
       "      <td>1</td>\n",
       "      <td>p</td>\n",
       "      <td>BAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Rodney Peete</td>\n",
       "      <td>30.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>34</td>\n",
       "      <td>58.8</td>\n",
       "      <td>269</td>\n",
       "      <td>7.91</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>17.8</td>\n",
       "      <td>qb</td>\n",
       "      <td>1996</td>\n",
       "      <td>1</td>\n",
       "      <td>p</td>\n",
       "      <td>PHI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Kerry Collins</td>\n",
       "      <td>24.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>31</td>\n",
       "      <td>54.8</td>\n",
       "      <td>198</td>\n",
       "      <td>6.39</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>17.3</td>\n",
       "      <td>17.3</td>\n",
       "      <td>qb</td>\n",
       "      <td>1996</td>\n",
       "      <td>1</td>\n",
       "      <td>p</td>\n",
       "      <td>CAR</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Rank              Name   Age   Exp  G Cmp Att   Cm%  PYd Y/Att  ... Rsh  \\\n",
       "0    1       Brett Favre  27.0   6.0  1  20  27  74.1  247  9.15  ...   1   \n",
       "1    2      Mark Brunell  26.0   3.0  1  20  31  64.5  212  6.84  ...  10   \n",
       "2    3  Vinny Testaverde  33.0  10.0  1  19  33  57.6  254  7.70  ...   8   \n",
       "3    4      Rodney Peete  30.0   8.0  1  20  34  58.8  269  7.91  ...   6   \n",
       "4    5     Kerry Collins  24.0   2.0  1  17  31  54.8  198  6.39  ...   1   \n",
       "\n",
       "  RshYd RshTD  FP/G FantPt Position  Year Week Scoring profile Team  \n",
       "0     1     0  26.0   26.0       qb  1996    1               p   GB  \n",
       "1    41     0  20.6   20.6       qb  1996    1               p  JAX  \n",
       "2    42     1  20.4   20.4       qb  1996    1               p  BAL  \n",
       "3    10     0  17.8   17.8       qb  1996    1               p  PHI  \n",
       "4    14     0  17.3   17.3       qb  1996    1               p  CAR  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df['Team']=data_df['Name'].apply(lambda x: x.split()[-1])\n",
    "data_df['Name']=data_df['Name'].apply(lambda x: ' '.join(x.split()[:-1]))\n",
    "data_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
